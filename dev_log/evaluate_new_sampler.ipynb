{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_JIT_USE_NNC_NOT_NVFUSER\"] = \"1\"\n",
    "from typing import List, Tuple, Optional, Union, Iterable\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from beartype import beartype\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from e3nn import o3\n",
    "\n",
    "from edf_interface.data import PointCloud, SE3, DemoDataset, TargetPoseDemo\n",
    "from diffusion_edf.gnn_data import FeaturedPoints\n",
    "from diffusion_edf import train_utils\n",
    "from diffusion_edf.trainer import DiffusionEdfTrainer\n",
    "from diffusion_edf.visualize import visualize_pose\n",
    "from diffusion_edf.agent import DiffusionEdfAgent\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "task_type = 'place'\n",
    "config_root_dir = 'configs/sapien'\n",
    "testset = DemoDataset(dataset_dir='demo/sapien_demo_20230625')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_root_dir, 'agent.yaml')) as f:\n",
    "    model_kwargs_list = yaml.load(f, Loader=yaml.FullLoader)['model_kwargs'][f\"{task_type}_models_kwargs\"]\n",
    "\n",
    "with open(os.path.join(config_root_dir, 'preprocess.yaml')) as f:\n",
    "    preprocess_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    unprocess_config = preprocess_config['unprocess_config']\n",
    "    preprocess_config = preprocess_config['preprocess_config']\n",
    "\n",
    "agent = DiffusionEdfAgent(\n",
    "    model_kwargs_list=model_kwargs_list,\n",
    "    preprocess_config=preprocess_config,\n",
    "    unprocess_config=unprocess_config,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Input Data and Initial Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo: TargetPoseDemo = testset[1][0 if task_type == 'pick' else 1 if task_type == 'place' else \"task_type must be either 'pick' or 'place'\"].to(device)\n",
    "scene_pcd: PointCloud = demo.scene_pcd\n",
    "grasp_pcd: PointCloud = demo.grasp_pcd\n",
    "T0 = torch.cat([\n",
    "    torch.tensor([[1., 0., 0.0, 0.]], device=device),\n",
    "    torch.tensor([[0., 0., 1.2]], device=device)\n",
    "], dim=-1)\n",
    "\n",
    "\n",
    "N_samples = 10\n",
    "Ts_init = SE3(poses=T0.repeat(N_samples,1)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts_out, scene_proc, grasp_proc = agent.sample(scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "                                              N_steps_list = [[250, 250], [250, 250]],\n",
    "                                              timesteps_list = [[0.02, 0.02], [0.02, 0.02]],\n",
    "                                              temperatures_list = [[1., 1.], [1., 1.]],\n",
    "                                              log_t_schedule=True,    # Original Behavior: False\n",
    "                                              time_exponent_temp=1.0, # Original Behavior: 0.5\n",
    "                                              time_exponent_alpha=0.5, # Original Behavior: 0.5\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization = TargetPoseDemo(\n",
    "    target_poses=SE3(poses=Ts_out[-1]),\n",
    "    scene_pcd=scene_proc,\n",
    "    grasp_pcd=grasp_proc\n",
    ")\n",
    "visualization = agent.unprocess_fn(visualization).to('cpu')\n",
    "visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "visualization = TargetPoseDemo(\n",
    "    target_poses=SE3(poses=torch.cat([Ts_out[::10, sample_idx], Ts_out[-1:, sample_idx]], dim=0)),\n",
    "    scene_pcd=scene_proc,\n",
    "    grasp_pcd=grasp_proc\n",
    ")\n",
    "visualization = agent.unprocess_fn(visualization).to('cpu')\n",
    "visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_model(self, T_seed: torch.Tensor,\n",
    "            scene_pcd_multiscale: List[FeaturedPoints], \n",
    "            grasp_pcd: FeaturedPoints,\n",
    "            diffusion_schedules: List[Union[\n",
    "                                    List[float], \n",
    "                                    Tuple[float, float]]\n",
    "                                ],\n",
    "            N_steps: List[int], \n",
    "            timesteps: List[float],\n",
    "            ang_noise_mult: Union[int, float] = 1.0,\n",
    "            lin_noise_mult: Union[int, float] = 1.0,\n",
    "            temperatures = 1.0,\n",
    "            linear_noise_schedule: bool = True) -> torch.Tensor:\n",
    "    from diffusion_edf import transforms\n",
    "\n",
    "    if isinstance(temperatures, int) or isinstance(temperatures, float):\n",
    "        temperatures = [float(temperatures) for _ in range(len(t_schedule))]\n",
    "    \n",
    "    device = T_seed.device\n",
    "    T = T_seed.clone().detach().type(torch.float64)\n",
    "\n",
    "    Ts = [T.clone().detach()]\n",
    "\n",
    "    diffusion_schedules = torch.tensor(diffusion_schedules, device=device, dtype=torch.float64)\n",
    "\n",
    "    steps = 0\n",
    "    for n, schedule in enumerate(diffusion_schedules):\n",
    "        temperature_base = float(temperatures[n])\n",
    "        t_schedule = torch.logspace(torch.log(schedule[0]), torch.log(schedule[1]), steps = N_steps[n], base=torch.e, device=device, dtype=torch.float64)\n",
    "        # t_schedule = torch.linspace(schedule[0], schedule[1], steps = N_steps[n], device=device, dtype=torch.float64)\n",
    "\n",
    "        t_schedule = t_schedule.unsqueeze(-1)\n",
    "        print(f\"{self.__class__.__name__}: sampling with (temperature: {temperature_base} || t_schedule: {schedule})\")\n",
    "        for i in tqdm(range(len(t_schedule))):\n",
    "            t = t_schedule[i]\n",
    "            temperature = temperature_base * torch.pow(t,1.0)\n",
    "            alpha_ang = (self.ang_mult **2) * torch.pow(t,0.5) * timesteps[n]\n",
    "            alpha_lin = (self.lin_mult **2) * torch.pow(t,0.5) * timesteps[n]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                (ang_score_dimless, lin_score_dimless) = self.score_head(Ts=T.view(-1,7).float(), \n",
    "                                                                         key_pcd_multiscale=scene_pcd_multiscale,\n",
    "                                                                         query_pcd=grasp_pcd,\n",
    "                                                                         time = t.repeat(len(T)).float())\n",
    "            ang_score_dimless, lin_score_dimless = ang_score_dimless.type(torch.float64), lin_score_dimless.type(torch.float64)\n",
    "            ang_score = ang_score_dimless / (self.ang_mult * torch.sqrt(t))\n",
    "            lin_score = lin_score_dimless / (self.lin_mult * torch.sqrt(t))\n",
    "\n",
    "            ang_noise = float(ang_noise_mult) * torch.sqrt(temperature*alpha_ang) * torch.randn_like(ang_score, dtype=torch.float64) \n",
    "            lin_noise = float(lin_noise_mult) * torch.sqrt(temperature*alpha_lin) * torch.randn_like(lin_score, dtype=torch.float64)\n",
    "\n",
    "            ang_disp = (alpha_ang/2) * ang_score + ang_noise\n",
    "            lin_disp = (alpha_lin/2) * lin_score + lin_noise\n",
    "\n",
    "            L = T.detach()[...,self.q_indices] * (self.q_factor.type(torch.float64))\n",
    "            q, x = T[...,:4], T[...,4:]\n",
    "            dq = torch.einsum('...ij,...j->...i', L, ang_disp)\n",
    "            dx = transforms.quaternion_apply(q, lin_disp)\n",
    "            q = transforms.normalize_quaternion(q + dq)\n",
    "            T = torch.cat([q, x+dx], dim=-1)\n",
    "\n",
    "            # dT = transforms.se3_exp_map(torch.cat([lin_disp, ang_disp], dim=-1))\n",
    "            # dT = torch.cat([transforms.matrix_to_quaternion(dT[..., :3, :3]), dT[..., :3, 3]], dim=-1)\n",
    "            # T = transforms.multiply_se3(T, dT)\n",
    "            steps += 1\n",
    "            Ts.append(T.clone().detach())\n",
    "\n",
    "    Ts.append(T.clone().detach())\n",
    "    Ts = torch.stack(Ts, dim=0).detach()\n",
    "\n",
    "    return Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_agent(self, scene_pcd: PointCloud, \n",
    "            grasp_pcd: PointCloud, \n",
    "            Ts_init: SE3,\n",
    "            N_steps_list: List[List[int]],\n",
    "            timesteps_list: List[List[float]],\n",
    "            temperatures_list,\n",
    "            diffusion_schedules_list = None,\n",
    "            ) -> Tuple[torch.Tensor, PointCloud, PointCloud]:\n",
    "    from diffusion_edf.gnn_data import FeaturedPoints, pcd_to_featured_points\n",
    "    if diffusion_schedules_list is None:\n",
    "        diffusion_schedules_list = [None for _ in range(len(self.models))]\n",
    "    assert len(self.models) == len(N_steps_list), f\"{len(self.models)} != {len(N_steps_list)}\"\n",
    "    assert len(self.models) == len(timesteps_list), f\"{len(self.models)} != {len(timesteps_list)}\"\n",
    "    assert len(self.models) == len(temperatures_list), f\"{len(self.models)} != {len(temperatures_list)}\"\n",
    "    assert len(self.models) == len(diffusion_schedules_list), f\"{len(self.models)} != {len(diffusion_schedules_list)}\"\n",
    "\n",
    "    scene_pcd: PointCloud = self.proc_fn(scene_pcd)\n",
    "    grasp_pcd: PointCloud = self.proc_fn(grasp_pcd)\n",
    "    Ts_init: SE3 = self.proc_fn(Ts_init)\n",
    "\n",
    "    scene_input: FeaturedPoints = pcd_to_featured_points(scene_pcd)\n",
    "    grasp_input: FeaturedPoints = pcd_to_featured_points(grasp_pcd)\n",
    "    T0: torch.Tensor = Ts_init.poses\n",
    "    assert T0.ndim == 2 and T0.shape[-1] == 7, f\"{T0.shape}\"\n",
    "\n",
    "    Ts_out = []\n",
    "    for model, N_steps, timesteps, temperatures, diffusion_schedules in zip(self.models, N_steps_list, timesteps_list, temperatures_list, diffusion_schedules_list):\n",
    "        #################### Feature extraction #####################\n",
    "        with torch.no_grad():\n",
    "            scene_out_multiscale: List[FeaturedPoints] = model.get_key_pcd_multiscale(scene_input)\n",
    "            grasp_out: FeaturedPoints = model.get_query_pcd(grasp_input)\n",
    "\n",
    "        if diffusion_schedules is None:\n",
    "            diffusion_schedules = model.diffusion_schedules\n",
    "        assert len(diffusion_schedules) == len(N_steps), f\"{len(diffusion_schedules)} != {len(N_steps)}\"\n",
    "        assert len(diffusion_schedules) == len(timesteps), f\"{len(diffusion_schedules)} != {len(timesteps)}\"\n",
    "\n",
    "        #################### Sample #####################\n",
    "        with torch.no_grad():\n",
    "            Ts = sample_model(model,\n",
    "                T_seed=T0.clone().detach(),\n",
    "                scene_pcd_multiscale=scene_out_multiscale,\n",
    "                grasp_pcd=grasp_out,\n",
    "                diffusion_schedules=diffusion_schedules,\n",
    "                N_steps=N_steps,\n",
    "                timesteps=timesteps,\n",
    "                temperatures=temperatures,\n",
    "                linear_noise_schedule = False\n",
    "            )\n",
    "            T0 = Ts[-1]\n",
    "            Ts_out.append(Ts)\n",
    "    Ts_out = torch.cat(Ts_out, dim=0).float() # Ts_out: (nTime, nSample, 7)\n",
    "\n",
    "    return Ts_out, scene_pcd, grasp_pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts_out, scene_proc, grasp_proc = sample_agent(self=agent,\n",
    "    scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "                                              N_steps_list = [[250, 250], [250, 250]],\n",
    "                                              timesteps_list = [[0.02, 0.02], [0.02, 0.02]],\n",
    "                                              temperatures_list = [[1., 1.], [1., 1.]])\n",
    "\n",
    "# Ts_out, scene_proc, grasp_proc = agent.sample(scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "#                                               N_steps_list = [[500, 500], [500, 1000]],\n",
    "#                                               timesteps_list = [[0.02, 0.02], [0.02, 0.02]],\n",
    "#                                               temperatures_list = [[1., 1.], [1., 1.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "visualization = TargetPoseDemo(\n",
    "    target_poses=SE3(poses=torch.cat([Ts_out[::10, sample_idx], Ts_out[-1:, sample_idx]], dim=0)),\n",
    "    scene_pcd=scene_proc,\n",
    "    grasp_pcd=grasp_proc\n",
    ")\n",
    "visualization = agent.unprocess_fn(visualization).to('cpu')\n",
    "visualization.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
