{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_JIT_USE_NNC_NOT_NVFUSER\"] = \"1\"\n",
    "# os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
    "from typing import List, Tuple, Optional, Union, Iterable\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from beartype import beartype\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from e3nn import o3\n",
    "\n",
    "from edf_interface.data import PointCloud, SE3, DemoDataset, TargetPoseDemo\n",
    "from diffusion_edf.gnn_data import FeaturedPoints\n",
    "from diffusion_edf import train_utils\n",
    "from diffusion_edf.trainer import DiffusionEdfTrainer\n",
    "from diffusion_edf.visualize import visualize_pose\n",
    "from diffusion_edf.agent import DiffusionEdfAgent\n",
    "\n",
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "torch.manual_seed(seed)\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "import random\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "# device = 'cpu'\n",
    "half_precision = False\n",
    "task_type = 'pick'\n",
    "config_root_dir = 'configs/ebm'\n",
    "\n",
    "testset = DemoDataset(dataset_dir='demo/panda_mug',\n",
    "                      device=device, \n",
    "                      dtype = torch.float16 if half_precision else torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(config_root_dir, 'agent.yaml')) as f:\n",
    "    model_kwargs_list = yaml.load(f, Loader=yaml.FullLoader)['model_kwargs'][f\"{task_type}_models_kwargs\"]\n",
    "\n",
    "with open(os.path.join(config_root_dir, 'preprocess.yaml')) as f:\n",
    "    preprocess_config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    unprocess_config = preprocess_config['unprocess_config']\n",
    "    preprocess_config = preprocess_config['preprocess_config']\n",
    "\n",
    "agent = DiffusionEdfAgent(\n",
    "    model_kwargs_list=model_kwargs_list,\n",
    "    preprocess_config=preprocess_config,\n",
    "    unprocess_config=unprocess_config,\n",
    "    device=device,\n",
    "    compile_score_head=False,\n",
    "    half_precision=half_precision\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_edf.emb_score_head import EbmScoreModelHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = agent.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_tensor_field_kwargs={\n",
    "    \"irreps_output\": o3.Irreps('64x0e+32x1e+16x2e'),\n",
    "    \"irreps_sh\": o3.Irreps(\"1x0e+1x1e+1x2e\"),\n",
    "    \"num_heads\": 4,\n",
    "    \"fc_neurons\": [-1, 128, 64],\n",
    "    \"length_emb_dim\": 64,\n",
    "    \"r_cluster_multiscale\": [6.,],\n",
    "    \"n_layers\": 1,\n",
    "    \"irreps_mlp_mid\": 3,\n",
    "    \"cutoff_method\": 'edge_attn',\n",
    "    \"r_mincut_nonscalar_sh\": 0.1\n",
    "}\n",
    "\n",
    "assert 'irreps_input' not in key_tensor_field_kwargs.keys()\n",
    "key_tensor_field_kwargs['irreps_input'] = model.key_model.irreps_output\n",
    "assert 'use_src_point_attn' not in key_tensor_field_kwargs.keys()\n",
    "key_tensor_field_kwargs['use_src_point_attn'] = False\n",
    "assert 'use_dst_point_attn' not in key_tensor_field_kwargs.keys()\n",
    "key_tensor_field_kwargs['use_dst_point_attn'] = False\n",
    "\n",
    "\n",
    "\n",
    "ebm_head = EbmScoreModelHead(\n",
    "    max_time=1.0,\n",
    "    time_emb_mlp=[512, 256, 128],\n",
    "    key_tensor_field_kwargs=key_tensor_field_kwargs,\n",
    "    irreps_query_edf=o3.Irreps('64x0e+32x1e+16x2e'),\n",
    "    lin_mult=15.,\n",
    "    ang_mult=2.5,\n",
    "    edge_time_encoding=True,\n",
    "    query_time_encoding=False\n",
    ").to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Input Data and Initial Pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo: TargetPoseDemo = testset[2][0 if task_type == 'pick' else 1 if task_type == 'place' else \"task_type must be either 'pick' or 'place'\"].to(device)\n",
    "scene_pcd: PointCloud = demo.scene_pcd\n",
    "grasp_pcd: PointCloud = demo.grasp_pcd\n",
    "Ts: SE3 = demo.target_poses\n",
    "# T0 = torch.cat([\n",
    "#     torch.tensor([[1., 0., 0.0, 0.]], device=device, dtype=scene_pcd.points.dtype),\n",
    "#     torch.tensor([[0., 0., 0.3]], device=device, dtype=scene_pcd.points.dtype)\n",
    "# ], dim=-1)\n",
    "# Ts_init = SE3(poses=T0).to(device, dtype=scene_pcd.points.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_edf import train_utils\n",
    "\n",
    "scene_pcd_proc: PointCloud = agent.proc_fn(scene_pcd)\n",
    "grasp_pcd_proc: PointCloud = agent.proc_fn(grasp_pcd)\n",
    "Ts_proc: SE3 = agent.proc_fn(Ts)\n",
    "\n",
    "scene_pcd_proc: FeaturedPoints = train_utils.pcd_to_featured_points(scene_pcd_proc)\n",
    "grasp_pcd_proc: FeaturedPoints = train_utils.pcd_to_featured_points(grasp_pcd_proc)\n",
    "Ts_proc: torch.Tensor = Ts_proc.poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    key_pcd_multiscale: List[FeaturedPoints] = model.get_key_pcd_multiscale(scene_pcd_proc)\n",
    "    query_pcd: FeaturedPoints = model.get_query_pcd(grasp_pcd_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    energy = ebm_head.compute_energy(\n",
    "        Ts=Ts_proc,\n",
    "        key_pcd_multiscale=key_pcd_multiscale,\n",
    "        query_pcd=query_pcd,\n",
    "        time=torch.tensor([1.], device=device)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_vel, lin_vel = ebm_head.forward(\n",
    "    Ts=Ts_proc,\n",
    "    key_pcd_multiscale=key_pcd_multiscale,\n",
    "    query_pcd=query_pcd,\n",
    "    time=torch.tensor([1.], device=device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_edf import transforms\n",
    "\n",
    "T = Ts_proc\n",
    "time = torch.tensor([1.], device=device)\n",
    "\n",
    "\n",
    "T = T.detach().requires_grad_(True)\n",
    "logP = -ebm_head.compute_energy(\n",
    "    Ts=T,\n",
    "    key_pcd_multiscale=key_pcd_multiscale,\n",
    "    query_pcd=query_pcd,\n",
    "    time=time\n",
    ")\n",
    "logP.sum().backward(inputs=T)\n",
    "grad = T.grad\n",
    "L = T.detach()[...,ebm_head.q_indices] * ebm_head.q_factor\n",
    "grad = torch.cat([transforms.quaternion_apply(transforms.quaternion_invert(T[...,:4].detach()), grad[...,4:]), torch.einsum('...ia,...i', L, grad[...,:4])], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdfasfda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts_out, scene_proc, grasp_proc = agent.sample(scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "                                              N_steps_list = [[250, 250], [250, 250]],\n",
    "                                              timesteps_list = [[0.02, 0.02], [0.02, 0.02]],\n",
    "                                              temperatures_list = [[1., 1.], [1., 1.]],\n",
    "                                              log_t_schedule = True,\n",
    "                                              time_exponent_temp = 1.0,\n",
    "                                              time_exponent_alpha = 0.5)\n",
    "\n",
    "# Ts_out, scene_proc, grasp_proc = agent.sample(scene_pcd=scene_pcd, grasp_pcd=grasp_pcd, Ts_init=Ts_init,\n",
    "#                                               N_steps_list = [[250, 250], [500, 500]],\n",
    "#                                               timesteps_list = [[0.04, 0.04], [0.04, 0.06]],\n",
    "#                                               temperatures_list = [[1., 1.], [0.5, 0.1]],\n",
    "#                                               diffusion_schedules_list=[\n",
    "#                                                   [[1., 0.1], [0.1, 0.1]],\n",
    "#                                                   [[0.1, 0.1], [0.03, 0.03] ],\n",
    "#                                                   ],\n",
    "#                                               log_t_schedule = False,\n",
    "#                                               time_exponent_temp = 1.0,\n",
    "#                                               time_exponent_alpha = 0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "visualization = TargetPoseDemo(\n",
    "    target_poses=SE3(poses=torch.cat([Ts_out[::10, sample_idx], Ts_out[-1:, sample_idx]], dim=0)),\n",
    "    scene_pcd=scene_proc,\n",
    "    grasp_pcd=grasp_proc\n",
    ")\n",
    "visualization = agent.unprocess_fn(visualization).to('cpu')\n",
    "visualization.show(bg_color=(0.3, 0.3, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
