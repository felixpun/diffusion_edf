{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import theseus as th\n",
    "from theseus import SO3\n",
    "\n",
    "class SO3_R3():\n",
    "    def __init__(self, R=None, t=None):\n",
    "        self.R = SO3()\n",
    "        if R is not None:\n",
    "            self.R.update(R)\n",
    "        self.w = self.R.log_map()\n",
    "        if t is not None:\n",
    "            self.t = t\n",
    "\n",
    "    def log_map(self):\n",
    "        return torch.cat((self.t, self.w), -1)\n",
    "\n",
    "    def exp_map(self, x):\n",
    "        self.t = x[..., :3]\n",
    "        self.w = x[..., 3:]\n",
    "        self.R = SO3().exp_map(self.w)\n",
    "        return self\n",
    "\n",
    "    def to_matrix(self):\n",
    "        H = torch.eye(4).unsqueeze(0).repeat(self.t.shape[0], 1, 1).to(self.t)\n",
    "        H[:, :3, :3] = self.R.to_matrix()\n",
    "        H[:, :3, -1] = self.t\n",
    "        return H\n",
    "\n",
    "    def sample(self, batch=1):\n",
    "        R = SO3().rand(batch)\n",
    "        t = torch.randn(batch, 3)\n",
    "        H = torch.eye(4).unsqueeze(0).repeat(batch, 1, 1).to(t)\n",
    "        H[:, :3, :3] = R.to_matrix()\n",
    "        H[:, :3, -1] = t\n",
    "        return H\n",
    "\n",
    "\n",
    "class SE3DenoisingLoss():\n",
    "\n",
    "    def __init__(self, field='denoise', delta = 1., grad=False):\n",
    "        self.field = field\n",
    "        self.delta = delta\n",
    "        self.grad = grad\n",
    "\n",
    "    # TODO check sigma value\n",
    "    def marginal_prob_std(self, t, sigma=0.5):\n",
    "        return torch.sqrt((sigma ** (2 * t) - 1.) / (2. * np.log(sigma)))\n",
    "\n",
    "    def log_gaussian_on_lie_groups(self, x, context):\n",
    "        R_p = SO3.exp_map(x[...,3:])\n",
    "        delta_H = th.compose(th.inverse(context[0]), R_p)\n",
    "        log = delta_H.log_map()\n",
    "\n",
    "        dt = x[...,:3] - context[1]\n",
    "\n",
    "        tlog = torch.cat((dt, log), -1)\n",
    "        return -0.5 * tlog.pow(2).sum(-1)/(context[2]**2)\n",
    "\n",
    "    def loss_fn(self, model, model_input, ground_truth, val=False, eps=1e-5):\n",
    "\n",
    "        ## From Homogeneous transformation to axis-angle ##\n",
    "        H = model_input['x_ene_pos']\n",
    "        n_grasps = H.shape[1]\n",
    "        c = model_input['visual_context']\n",
    "        model.set_latent(c, batch=n_grasps)\n",
    "\n",
    "        H_in = H.reshape(-1, 4, 4)\n",
    "        H_in = SO3_R3(R=H_in[:, :3, :3], t=H_in[:, :3, -1])\n",
    "        tw = H_in.log_map()\n",
    "        #######################\n",
    "\n",
    "        ## 1. Compute noisy sample SO(3) + R^3##\n",
    "        random_t = torch.rand_like(tw[...,0], device=tw.device) * (1. - eps) + eps\n",
    "        z = torch.randn_like(tw)\n",
    "        std = self.marginal_prob_std(random_t)\n",
    "        noise = z * std[..., None]\n",
    "        noise_t = noise[..., :3]\n",
    "        noise_rot = SO3.exp_map(noise[...,3:])\n",
    "        R_p = th.compose(H_in.R, noise_rot)\n",
    "        t_p = H_in.t + noise_t\n",
    "        #############################\n",
    "\n",
    "        ## 2. Compute target score ##\n",
    "        w_p = R_p.log_map()\n",
    "        tw_p = torch.cat((t_p, w_p), -1).requires_grad_()\n",
    "        log_p = self.log_gaussian_on_lie_groups(tw_p, context=[H_in.R, H_in.t, std])\n",
    "        target_grad = torch.autograd.grad(log_p.sum(), tw_p, only_inputs=True)[0]\n",
    "        target_score = target_grad.detach()\n",
    "        #############################\n",
    "\n",
    "        ## 3. Get diffusion grad ##\n",
    "        x_in = tw_p.detach().requires_grad_(True)\n",
    "        H_in = SO3_R3().exp_map(x_in).to_matrix()\n",
    "        t_in = random_t\n",
    "        energy = model(H_in, t_in)\n",
    "        grad_energy = torch.autograd.grad(energy.sum(), x_in, only_inputs=True,\n",
    "                                          retain_graph=True, create_graph=True)[0]\n",
    "\n",
    "        ## 4. Compute loss ##\n",
    "        loss_fn = nn.L1Loss()\n",
    "        loss = loss_fn(grad_energy, -target_score)/20.\n",
    "\n",
    "        info = {self.field: energy}\n",
    "        loss_dict = {\"Score loss\": loss}\n",
    "        return loss_dict, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SE3DenoisingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SE3DenoisingLoss at 0x7f3b767f68e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
