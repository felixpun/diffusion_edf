{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"PYTORCH_JIT_USE_NNC_NOT_NVFUSER\"] = \"1\"\n",
    "from typing import List, Tuple, Optional, Union, Iterable, NamedTuple, Any, Sequence\n",
    "\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from e3nn import o3\n",
    "\n",
    "from diffusion_edf.data import DemoSeqDataset, DemoSequence, TargetPoseDemo\n",
    "from diffusion_edf.gnn_data import FeaturedPoints, merge_featured_points, GraphEdge\n",
    "from diffusion_edf import train_utils\n",
    "from diffusion_edf import preprocess\n",
    "from diffusion_edf.feature_extractor import UnetFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'\n",
    "task = 'pick'\n",
    "eval = True\n",
    "compile = True\n",
    "\n",
    "model_configs_dir = 'configs/test/model_configs.yaml'\n",
    "train_configs_dir = 'configs/test/train_configs.yaml'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load configs, preprocessor, and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_configs_dir) as file:\n",
    "    model_configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "with open(train_configs_dir) as file:\n",
    "    train_configs = yaml.load(file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_fn = []\n",
    "for proc in train_configs['preprocess_config']:\n",
    "    proc_fn.append(\n",
    "        getattr(preprocess, proc['name'])(**proc['configs'])\n",
    "    )\n",
    "proc_fn = Compose(proc_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = train_utils.get_collate_fn(task=task, proc_fn=proc_fn)\n",
    "trainset = DemoSeqDataset(dataset_dir=train_configs['dataset_dir'], annotation_file=train_configs['annotation_file'], device=device)\n",
    "train_dataloader = DataLoader(trainset, shuffle=True, collate_fn=collate_fn, batch_size=train_configs['n_batches'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = UnetFeatureExtractor(**model_configs['scene']['feature_extractor_configs']).to(device)\n",
    "if compile:\n",
    "    feature_extractor = torch.jit.script(feature_extractor)\n",
    "if eval:\n",
    "    feature_extractor = feature_extractor.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for demo_batch in train_dataloader:\n",
    "    B = len(demo_batch)\n",
    "    scene_pcd, grasp_pcd, target_poses = train_utils.flatten_batch(demo_batch=demo_batch)\n",
    "    input_pcd = FeaturedPoints(\n",
    "        x=scene_pcd.x/model_configs['unit_len'],\n",
    "        f=scene_pcd.f,\n",
    "        b=scene_pcd.b\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = feature_extractor(input_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def func(x: List[Tuple[int, Tuple[int, int]]]) -> List[Tuple[int, Tuple[int, int]]]:\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irreps = o3.Irreps(model_configs['scene']['feature_extractor_configs']['irreps_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func(irreps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale = 3\n",
    "# node_coord = output[scale].x\n",
    "# node_feature = output[scale].f\n",
    "# node_batch = output[scale].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion_edf.transforms import quaternion_apply, random_quaternions\n",
    "rot = random_quaternions(1, device=device)\n",
    "rot = rot/rot.norm(dim=-1, keepdim=True)\n",
    "trans = torch.randn(3,device=device)\n",
    "node_coord_rot = quaternion_apply(rot, node_coord) + trans\n",
    "\n",
    "\n",
    "node_feature_rot = node_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_val_rot, edf_info_rot = edf.forward(query_coord=query_coord_rot, query_batch=query_batch, node_feature=node_feature_rot, node_coord=node_coord_rot, batch=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "irrep_transform = e3nn_script(TransformFeatureQuaternion(irreps = o3.Irreps(edf.irreps_emb), device=device))\n",
    "a = field_val_rot\n",
    "b = field_val\n",
    "isclose = torch.isclose(irrep_transform(b, rot)[0], a, atol=0.01, rtol=0.01)\n",
    "# print(isclose)\n",
    "print(f\"Equivariance ratio: {(isclose.sum() / len(a.view(-1))).item()}\") # Slight non-equivariance comes from FPS downsampling algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff_edf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79a0085b6cf04e1cff261ad12d41cff4e1530d9e68d1f8fc6bd159a2915452c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
